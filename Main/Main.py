import os
import sys
import numpy as np
import torch
import torch.jit
import cv2
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
import math
from PyQt5.QtWidgets import (QApplication, QMainWindow, QPushButton, QVBoxLayout,
                             QHBoxLayout, QLabel, QFileDialog, QWidget, QProgressBar,
                             QStatusBar, QTabWidget, QSpinBox, QDoubleSpinBox,
                             QComboBox, QMessageBox, QTextEdit, QTableWidget,
                             QTableWidgetItem, QHeaderView, QLineEdit, QGridLayout,
                             QGroupBox, QFrame, QInputDialog)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QSize, QTimer
from PyQt5.QtGui import QPixmap, QImage, QFont, QIcon
import pandas as pd
import io
import base64
import tempfile # For temporary file handling

# --- Encryption/Decryption Dependencies ---
try:
    from cryptography.fernet import Fernet, InvalidToken
    from cryptography.hazmat.primitives import hashes
    from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
    from cryptography.hazmat.backends import default_backend
    CRYPTO_AVAILABLE = True
except ImportError:
    CRYPTO_AVAILABLE = False
    print("FATAL ERROR: 'cryptography' library not found. Application cannot run.")
    # Attempt to show a message box even before app fully starts
    # Note: This might not always work depending on when the import fails
    try:
        app_temp = QApplication.instance() or QApplication(sys.argv)
        msg_box = QMessageBox()
        msg_box.setIcon(QMessageBox.Critical)
        msg_box.setWindowTitle("Dependency Error")
        msg_box.setText("Required library 'cryptography' is missing.")
        msg_box.setInformativeText("Please install it using: pip install cryptography")
        msg_box.exec_()
    except Exception as e:
        print(f"Could not show graphical error message: {e}")
    sys.exit(1) # Exit immediately

# --- Configuration Constants ---
# !!! IMPORTANT: These MUST match the values used in encrypt_weights.py !!!
SALT_SIZE = 16
PBKDF2_ITERATIONS = 390000
# Name of the encrypted file generated by encrypt_weights.py and to be embedded
EMBEDDED_ENCRYPTED_FILENAME = "encrypted_model.bin"
# Set this to the ORIGINAL type of your model file before encryption
# Use '.pt' for TorchScript or '.pth' for State Dict
ORIGINAL_MODEL_TYPE = '.pth' # <<<--- MUST SET THIS CORRECTLY (e.g., '.pt' or '.pth')
# Set the expected number of classes if using a .pth model that requires it
EXPECTED_NUM_CLASSES = 2
# --- End Configuration ---


# --- Helper Classes and Functions ---
class ToTensor:
    """自定义ToTensor变换，用于兼容性"""
    def __call__(self, pic):
        if isinstance(pic, np.ndarray):
            if pic.ndim == 2: pic = pic[:, :, np.newaxis]
            img = pic.transpose((2, 0, 1))
            img = img.astype(np.float32) / 255.0
            return torch.from_numpy(img)
        else:
            raise TypeError(f'pic应为ndarray，而不是{type(pic)}')

class Compose:
    """自定义Compose类，用于变换链"""
    def __init__(self, transforms): self.transforms = transforms
    def __call__(self, img):
        for t in self.transforms: img = t(img)
        return img

def get_instance_segmentation_model(num_classes):
    """
    Creates a Mask R-CNN model structure.
    Needed only if ORIGINAL_MODEL_TYPE is '.pth'.
    """
    try:
        # Try modern import first
        from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights
        try:
            # Try loading with specific weights enum if available (torchvision >= 0.13)
             weights = MaskRCNN_ResNet50_FPN_Weights.DEFAULT
             model = maskrcnn_resnet50_fpn(weights=weights)
             # Replace heads for custom classes
             from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
             from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
             in_features = model.roi_heads.box_predictor.cls_score.in_features
             model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
             in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
             hidden_layer = 256
             model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)
             print("Model structure created using modern torchvision API (weights.DEFAULT).")
             return model
        except AttributeError: # Fallback for slightly older torchvision where enum isn't used exactly like this
            # Try loading pretrained=True (deprecated but might work)
             model = maskrcnn_resnet50_fpn(weights='DEFAULT') # Or pretrained=True
             from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
             from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor
             in_features = model.roi_heads.box_predictor.cls_score.in_features
             model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
             in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
             hidden_layer = 256
             model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)
             print("Model structure created using older torchvision API (weights='DEFAULT').")
             return model

    except Exception as e1:
        print(f"Error creating model using standard import: {e1}")
        # Fallback if the above fails (e.g., very old torchvision or name changes)
        try:
            import torchvision
            from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
            from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor

            # Load pre-trained model structure
            model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=None) # Start without weights

            # Replace the classifier head
            in_features = model.roi_heads.box_predictor.cls_score.in_features
            model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

            # Replace the mask predictor head
            in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
            hidden_layer = 256 # Default hidden layer size in torchvision
            model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,
                                                               hidden_layer,
                                                               num_classes)
            print("Model structure created using fallback torchvision method.")
            return model
        except Exception as e2:
            print(f"Fallback model creation failed: {e2}")
            QMessageBox.critical(None, "Model Creation Error",
                                 f"Failed to create required model structure (MaskRCNN).\n"
                                 f"Error 1: {e1}\nError 2: {e2}\n"
                                 "Please check PyTorch/Torchvision installation and compatibility.")
            sys.exit(1) # Cannot proceed if model structure cannot be built

def resource_path(relative_path):
    """ Get absolute path to resource, works for dev and for PyInstaller """
    try:
        # PyInstaller creates a temp folder and stores path in _MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        # _MEIPASS not defined, use current directory
        base_path = os.path.abspath(".")
    return os.path.join(base_path, relative_path)

def preprocess_image(image_path):
    """Loads and preprocesses an image."""
    original_image = cv2.imread(image_path)
    if original_image is None:
        raise FileNotFoundError(f"无法读取图像文件: {image_path}")
    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB) # Convert to RGB
    transform = Compose([ToTensor()])
    image_tensor = transform(original_image)
    return image_tensor, original_image

def detect_regions(model, image_tensor, device, threshold=0.5):
    """Performs region detection using the model."""
    model.eval() # Ensure model is in evaluation mode
    image_tensor = image_tensor.to(device)
    with torch.no_grad():
        # Add batch dimension
        image_batch = [image_tensor] # Standard model expects a list
        # TorchScript model might expect a single tensor with batch dim
        # Note: TorchScript models loaded via torch.jit.load *usually* handle list input,
        # but if not, you might need: image_batch = image_tensor.unsqueeze(0)
        prediction = model(image_batch)[0] # Get first item from batch output

    # Filter by threshold
    keep = prediction['scores'] >= threshold
    filtered_prediction = {
        'boxes': prediction['boxes'][keep],
        'labels': prediction['labels'][keep],
        'scores': prediction['scores'][keep],
        'masks': prediction['masks'][keep]
    }
    return filtered_prediction

def calculate_equivalent_radius(area):
    """Calculates the equivalent radius of a circle with the given area."""
    if area < 0: return 0
    return math.sqrt(area / math.pi)

def visualize_results(image, prediction, threshold=0.5):
    """Draws masks and bounding boxes on the image and calculates stats."""
    vis_image = image.copy()
    height, width = image.shape[:2]
    boxes = prediction['boxes'].cpu().numpy()
    scores = prediction['scores'].cpu().numpy()

    # Ensure masks are handled correctly, even if empty or single
    if prediction['masks'].numel() == 0:
        masks = np.empty((0, height, width), dtype=np.float32)
    else:
        # Squeeze might remove dimension if only one mask exists, handle that
        masks_squeezed = prediction['masks'].squeeze(1).cpu().numpy()
        if masks_squeezed.ndim == 2 and len(boxes) == 1:
             masks = np.expand_dims(masks_squeezed, axis=0) # Add batch dim back
        elif masks_squeezed.ndim == 3:
             masks = masks_squeezed
        else: # Unexpected shape, create empty
             masks = np.empty((0, height, width), dtype=np.float32)


    region_info = []
    if len(masks) > 0 and len(boxes) > 0 and len(masks) == len(boxes):
        for i in range(len(boxes)):
            # Use mask threshold 0.5 to create binary mask
            binary_mask = (masks[i] > 0.5).astype(np.uint8)
            area = np.sum(binary_mask)
            if area > 0:
                radius = calculate_equivalent_radius(area)
                # Store detailed info for sorting and table display
                region_info.append({
                    'index': i,             # Original index from prediction
                    'area': area,
                    'radius': radius,
                    'box': boxes[i],
                    'mask': binary_mask,    # Store the binary mask
                    'score': scores[i]      # Store the confidence score
                })

    # Sort regions by area (largest first) for consistent numbering
    region_info.sort(key=lambda x: x['area'], reverse=True)

    final_areas = []
    final_radii = []

    # Draw sorted regions
    for region_num, region in enumerate(region_info, 1):
        area = region['area']
        radius = region['radius']
        binary_mask = region['mask']
        color = np.random.randint(50, 255, 3).tolist() # Random color

        # Apply colored mask overlay
        colored_mask_overlay = np.zeros_like(vis_image)
        for c in range(3):
            colored_mask_overlay[:, :, c] = color[c]
        # Apply mask where binary_mask is 1
        masked_area = (binary_mask[:, :, np.newaxis] * colored_mask_overlay).astype(np.uint8)
        vis_image = cv2.addWeighted(vis_image, 1.0, masked_area, 0.5, 0) # Blend overlay

        # Draw bounding box
        x1, y1, x2, y2 = region['box'].astype(int)
        cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 2)

        # Put region number text
        cv2.putText(vis_image, f"#{region_num}", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        final_areas.append(area)
        final_radii.append(radius)

    # Calculate overall statistics
    count = len(region_info)
    total_area = sum(final_areas)
    avg_radius = sum(final_radii) / count if count > 0 else 0
    average_area = total_area / count if count > 0 else 0

    # Add summary text overlay
    text_color = (255, 255, 255); bg_color = (0, 0, 0)
    font = cv2.FONT_HERSHEY_SIMPLEX; scale = 0.7; thickness = 1; pad = 8
    texts = [f"数量 (Count): {count}",
             f"总面积 (Total Area): {total_area:.1f} px",
             f"平均半径 (Avg. Radius): {avg_radius:.2f} px"]
    y_offset = 30
    for text in texts:
        (w, h), _ = cv2.getTextSize(text, font, scale, thickness)
        # Draw background rectangle for text
        cv2.rectangle(vis_image, (pad, y_offset - h - pad//2), (pad + w + pad, y_offset + pad//2), bg_color, -1)
        # Draw text
        cv2.putText(vis_image, text, (pad + pad//2, y_offset), font, scale, text_color, thickness)
        y_offset += h + pad + 5 # Move down for next line

    results = {
        'count': count,
        'areas': final_areas, # Areas in sorted order
        'radii': final_radii, # Radii in sorted order
        'total_area': total_area,
        'average_area': average_area,
        'average_radius': avg_radius,
        'region_info': region_info, # Detailed info, sorted by area
        'visualization': vis_image # Image with overlays
    }
    return results


# --- Processing Thread ---
class ProcessingThread(QThread):
    """Runs image processing in a separate thread."""
    update_progress = pyqtSignal(int)
    processing_complete = pyqtSignal(dict)
    processing_error = pyqtSignal(str)

    def __init__(self, model, image_path, threshold=0.5, device=torch.device('cpu')):
        super().__init__()
        self.model = model
        self.image_path = image_path
        self.threshold = threshold
        self.device = device # Receive device from main thread

    def run(self):
        try:
            self.update_progress.emit(10)
            # Ensure model is on the correct device within the thread
            self.model = self.model.to(self.device)
            image_tensor, original_image = preprocess_image(self.image_path)
            self.update_progress.emit(30)

            prediction = detect_regions(self.model, image_tensor, self.device, self.threshold)
            self.update_progress.emit(70)

            results = visualize_results(original_image, prediction, self.threshold)
            self.update_progress.emit(95)

            results['original_image'] = original_image # Add original image for display
            self.update_progress.emit(100)
            self.processing_complete.emit(results)

        except FileNotFoundError as e:
             self.processing_error.emit(f"文件错误: {e}")
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            print(f"Error during processing thread:\n{error_details}")
            self.processing_error.emit(f"处理时发生意外错误: {type(e).__name__} - {e}\nDetails:\n{error_details}")


# --- Matplotlib Canvas Widget ---
class MplCanvas(FigureCanvas):
    """Embeddable Matplotlib canvas."""
    def __init__(self, parent=None, width=8, height=6, dpi=100):
        self.fig = Figure(figsize=(width, height), dpi=dpi)
        self.fig.patch.set_alpha(0) # Transparent background
        self.axes = self.fig.add_subplot(111)
        self.axes.patch.set_alpha(0) # Transparent axes background
        self.axes.axis('off') # Start with axes off
        super(MplCanvas, self).__init__(self.fig)
        self.setParent(parent)
        self.setStyleSheet("background-color:transparent;")
        self.fig.tight_layout(pad=0.5) # Adjust layout


# --- Main Application Window ---
class RegionDetectorApp(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("区域检测器 (受保护)")
        self.setMinimumSize(1200, 800)

        self.model = None
        self.current_image_path = None
        self.current_results = None
        self.device = torch.device('cpu') # Default to CPU

        # Attempt to set CUDA device if available
        if torch.cuda.is_available():
            try:
                torch.cuda.get_device_name(0) # Check if device is accessible
                self.device = torch.device('cuda')
                print("CUDA device found and accessible.")
            except RuntimeError as e:
                print(f"CUDA found but not accessible ({e}), using CPU.")
        else:
            print("CUDA not available, using CPU.")

        self.setup_ui()
        self.statusBar().showMessage("正在初始化，请稍候...")

        # Use QTimer to delay the password prompt until the main event loop starts
        QTimer.singleShot(150, self._prompt_and_load_model)

    def _prompt_and_load_model(self):
        """Prompts user for password and attempts to load the encrypted model."""
        if not CRYPTO_AVAILABLE:
             # This case should ideally be caught on startup, but double-check
             QMessageBox.critical(self, "错误", "加密库 'cryptography' 未安装或无法加载。\n无法解密模型。")
             self.statusBar().showMessage("错误：缺少加密库")
             self._set_ui_state_post_load(success=False)
             return

        password, ok = QInputDialog.getText(self, "需要密码", "请输入模型密码:", QLineEdit.Password)

        if ok and password:
            self.statusBar().showMessage("正在解密和加载模型，请稍候...")
            QApplication.processEvents() # Update the UI to show the message
            # Use QTimer to allow the message to display before intensive load starts
            QTimer.singleShot(50, lambda: self._process_model_loading(password))
        elif ok and not password:
             QMessageBox.warning(self, "密码错误", "密码不能为空。")
             self.statusBar().showMessage("模型加载取消 (空密码)")
             self._set_ui_state_post_load(success=False)
        else:
            # User pressed Cancel
            self.statusBar().showMessage("模型加载已取消。应用无法使用。")
            self._set_ui_state_post_load(success=False)
            # Consider closing the app if the model is essential
            # self.close()

    def _process_model_loading(self, password):
        """Wrapper function to perform loading and update UI state."""
        success = self._load_encrypted_model(password)
        self._set_ui_state_post_load(success)

    def _load_encrypted_model(self, password):
        """Loads and decrypts the embedded model file using the provided password."""
        temp_model_path = None # Path to the temporary file
        decrypted_data = None  # Store decrypted data temporarily
        key = None             # Ensure key is cleared
        cipher_suite = None    # Ensure cipher suite is cleared

        try:
            encrypted_file_path = resource_path(EMBEDDED_ENCRYPTED_FILENAME)
            print(f"Attempting to load encrypted model from: {encrypted_file_path}")

            if not os.path.exists(encrypted_file_path):
                raise FileNotFoundError(f"Embedded encrypted model file not found: {encrypted_file_path}")

            # 1. Read Salt and Encrypted Data
            with open(encrypted_file_path, 'rb') as f_enc:
                salt = f_enc.read(SALT_SIZE)
                encrypted_data = f_enc.read() # Read the rest of the file

            if len(salt) != SALT_SIZE:
                raise ValueError("Encrypted file is corrupted or too short (invalid salt).")

            # 2. Derive Key from Password and Salt
            print(f"Deriving key from password (using {PBKDF2_ITERATIONS} iterations)...")
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA256(),
                length=32, # Fernet key size
                salt=salt,
                iterations=PBKDF2_ITERATIONS,
                backend=default_backend()
            )
            key = base64.urlsafe_b64encode(kdf.derive(password.encode()))
            print("Key derived.")

            # 3. Decrypt Data
            cipher_suite = Fernet(key)
            print("Attempting decryption...")
            decrypted_data = cipher_suite.decrypt(encrypted_data)
            print(f"Decryption successful. Data size: {len(decrypted_data)} bytes.")

            # Clear sensitive data from memory as soon as possible
            del encrypted_data
            key = None
            cipher_suite = None
            kdf = None # Not strictly necessary but good practice

            # 4. Write Decrypted Data to a Temporary File
            # Use delete=False so we can close it and pass the path to torch.load
            with tempfile.NamedTemporaryFile(delete=False, suffix=ORIGINAL_MODEL_TYPE) as temp_f:
                temp_model_path = temp_f.name
                temp_f.write(decrypted_data)
                # temp_f.flush() # Ensure data is written (usually handled by close)
                # os.fsync(temp_f.fileno()) # Force OS sync (might be overkill)
            print(f"Decrypted data written to temporary file: {temp_model_path}")

            # No longer need the decrypted data in memory
            del decrypted_data

            # 5. Load Model from the Temporary File Path
            print(f"Loading model (Original Type: {ORIGINAL_MODEL_TYPE}) from temporary file...")

            if ORIGINAL_MODEL_TYPE == '.pt':
                # Load TorchScript model from the temporary file path
                self.model = torch.jit.load(temp_model_path, map_location=self.device)
                print("TorchScript model loaded successfully.")
            elif ORIGINAL_MODEL_TYPE == '.pth':
                # Load State Dict model
                # First, create the model structure
                self.model = get_instance_segmentation_model(num_classes=EXPECTED_NUM_CLASSES)
                # Load the state dict from the temporary file path
                state_dict = torch.load(temp_model_path, map_location=self.device)
                # Handle potential 'module.' prefix if saved using DataParallel
                if list(state_dict.keys())[0].startswith('module.'):
                    state_dict = {k[len("module."):]: v for k, v in state_dict.items()}
                self.model.load_state_dict(state_dict)
                self.model = self.model.to(self.device)
                self.model.eval() # Set to evaluation mode
                print("State Dict model loaded successfully.")
            else:
                raise ValueError(f"Unsupported ORIGINAL_MODEL_TYPE specified: {ORIGINAL_MODEL_TYPE}")

            return True # Loading successful

        except FileNotFoundError as e:
            print(f"Error: {e}")
            QMessageBox.critical(self, "加载错误", f"内部模型文件丢失: {EMBEDDED_ENCRYPTED_FILENAME}\n请确保应用已正确打包。\n错误: {e}")
            self.model = None
            return False
        except InvalidToken:
            print("Error: Decryption failed - Invalid password or corrupted file.")
            QMessageBox.critical(self, "密码错误", "密码不正确或加密文件已损坏。")
            self.model = None
            return False
        except ValueError as e: # Catch specific errors like bad salt
            print(f"Error loading/decrypting: {e}")
            QMessageBox.critical(self, "加载错误", f"加载或解密模型时出错: {e}")
            self.model = None
            return False
        except RuntimeError as e: # Catch PyTorch runtime errors during load
             print(f"PyTorch Runtime Error during load: {e}")
             import traceback
             traceback.print_exc()
             QMessageBox.critical(self, "模型加载失败", f"加载模型时发生运行时错误 (可能文件损坏或不兼容):\n{e}")
             self.model = None
             return False
        except Exception as e: # Catch any other unexpected errors
            print(f"Unexpected error loading/decrypting embedded model: {type(e).__name__} - {e}")
            import traceback
            error_details = traceback.format_exc()
            print(error_details)
            QMessageBox.critical(self, "严重错误", f"加载或解密内部模型时发生意外错误:\n{type(e).__name__}: {e}\n\nDetails:\n{error_details}")
            self.model = None
            return False
        finally:
            # --- IMPORTANT: Clean up the temporary file ---
            if temp_model_path and os.path.exists(temp_model_path):
                try:
                    os.remove(temp_model_path)
                    print(f"Temporary model file deleted: {temp_model_path}")
                except Exception as e_del:
                    # Log warning but don't crash the app
                    print(f"Warning: Could not delete temporary file {temp_model_path}: {e_del}")
            # Explicitly clear potentially sensitive variables from local scope
            key = None
            cipher_suite = None
            password = None # Clear password from memory if passed directly


    def _set_ui_state_post_load(self, success):
        """Updates status bar and enables/disables buttons based on model load success."""
        if success and self.model:
            self.statusBar().showMessage(f"模型已成功加载。使用设备: {self.device}")
            self.browse_image_btn.setEnabled(True) # Enable image loading
            self.process_btn.setEnabled(False)    # Process enabled only after image load
            self.save_btn.setEnabled(False)       # Save enabled only after processing
        else:
            # Status message should be set by the calling function (_prompt_and_load_model or _load_encrypted_model)
            self.browse_image_btn.setEnabled(False)
            self.process_btn.setEnabled(False)
            self.save_btn.setEnabled(False)

    def setup_ui(self):
        """Sets up the user interface components."""
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)

        # --- Input Group ---
        input_group = QGroupBox("输入 (Input)")
        input_layout = QGridLayout()
        input_group.setLayout(input_layout)

        # Image Path (Row 0)
        input_layout.addWidget(QLabel("图像路径 (Image Path):"), 0, 0)
        self.image_path_edit = QLineEdit()
        self.image_path_edit.setReadOnly(True)
        input_layout.addWidget(self.image_path_edit, 0, 1)
        self.browse_image_btn = QPushButton("浏览 (Browse)...")
        self.browse_image_btn.clicked.connect(self.load_image_dialog)
        self.browse_image_btn.setEnabled(False) # Disabled until model loads
        input_layout.addWidget(self.browse_image_btn, 0, 2)

        # Threshold (Row 1)
        input_layout.addWidget(QLabel("检测阈值 (Threshold):"), 1, 0)
        self.threshold_spin = QDoubleSpinBox()
        self.threshold_spin.setRange(0.01, 0.99)
        self.threshold_spin.setValue(0.5)
        self.threshold_spin.setSingleStep(0.05)
        input_layout.addWidget(self.threshold_spin, 1, 1)

        # Process Button (Row 1)
        self.process_btn = QPushButton("处理图像 (Process Image)")
        self.process_btn.clicked.connect(self.process_current_image)
        self.process_btn.setEnabled(False) # Disabled until image loaded
        input_layout.addWidget(self.process_btn, 1, 2)

        main_layout.addWidget(input_group)

        # --- Output Group ---
        output_group = QGroupBox("输出 (Output)")
        output_layout = QVBoxLayout()
        output_group.setLayout(output_layout)

        self.tab_widget = QTabWidget()

        # Visualization Tab
        self.viz_tab = QWidget()
        viz_layout = QVBoxLayout(self.viz_tab)
        images_layout = QHBoxLayout() # Layout for original and result images side-by-side
        # Original Image Display
        original_frame = QFrame()
        original_frame.setFrameShape(QFrame.StyledPanel)
        original_layout = QVBoxLayout(original_frame)
        original_layout.addWidget(QLabel("原始图像 (Original)", alignment=Qt.AlignCenter))
        self.original_canvas = MplCanvas(self, width=6, height=5, dpi=100)
        original_layout.addWidget(self.original_canvas)
        # Result Image Display
        result_frame = QFrame()
        result_frame.setFrameShape(QFrame.StyledPanel)
        result_layout = QVBoxLayout(result_frame)
        result_layout.addWidget(QLabel("检测结果 (Result)", alignment=Qt.AlignCenter))
        self.result_canvas = MplCanvas(self, width=6, height=5, dpi=100)
        result_layout.addWidget(self.result_canvas)
        images_layout.addWidget(original_frame)
        images_layout.addWidget(result_frame)
        viz_layout.addLayout(images_layout)
        # Save Button
        self.save_btn = QPushButton("保存结果 (Save Results)")
        self.save_btn.clicked.connect(self.save_results)
        self.save_btn.setEnabled(False) # Disabled until processing is complete
        viz_layout.addWidget(self.save_btn, 0, Qt.AlignCenter) # Center the save button

        # Detailed Results Tab
        self.results_tab = QWidget()
        results_layout = QVBoxLayout(self.results_tab)
        # Results Table
        self.results_table = QTableWidget()
        self.results_table.setColumnCount(4) # Index, Area, Radius, Score
        self.results_table.setHorizontalHeaderLabels(["区域 #", "面积 (px)", "等效半径 (px)", "置信度"])
        self.results_table.horizontalHeader().setSectionResizeMode(QHeaderView.Stretch)
        self.results_table.setEditTriggers(QTableWidget.NoEditTriggers) # Read-only
        results_layout.addWidget(self.results_table)
        # Summary Text View
        results_layout.addWidget(QLabel("结果摘要 (Summary):"))
        self.summary_text = QTextEdit()
        self.summary_text.setReadOnly(True)
        self.summary_text.setMaximumHeight(150) # Limit height
        results_layout.addWidget(self.summary_text)

        # Add tabs to widget
        self.tab_widget.addTab(self.viz_tab, "可视化 (Visualization)")
        self.tab_widget.addTab(self.results_tab, "详细数据 (Detailed Data)")
        output_layout.addWidget(self.tab_widget)
        main_layout.addWidget(output_group, 1) # Allow output group to stretch

        # --- Progress Bar ---
        self.progress_bar = QProgressBar()
        self.progress_bar.setRange(0, 100)
        self.progress_bar.setValue(0)
        self.progress_bar.setTextVisible(True)
        main_layout.addWidget(self.progress_bar)

        # --- Status Bar (created automatically) ---
        self.statusBar() # Ensure status bar exists


    def load_image_dialog(self):
        """Opens a dialog to select an image file."""
        # This button should only be enabled if the model is loaded
        if not self.model:
            QMessageBox.warning(self, "模型未加载", "模型尚未成功加载，请重启应用并输入正确密码。")
            return

        options = QFileDialog.Options()
        options |= QFileDialog.ReadOnly
        file_path, _ = QFileDialog.getOpenFileName(self, "加载图像 (Load Image)", "",
                                                   "图像文件 (*.png *.jpg *.jpeg *.bmp *.tiff);;所有文件 (*)",
                                                   options=options)
        if file_path:
            self.current_image_path = file_path
            self.image_path_edit.setText(os.path.basename(file_path)) # Show only filename
            self.statusBar().showMessage(f"图像已加载: {os.path.basename(file_path)}")
            try:
                # Use preprocessing func to load and check, but only display original
                _, img_rgb = preprocess_image(file_path) # Load as RGB numpy array

                # Display original image
                self.original_canvas.axes.cla()
                self.original_canvas.axes.imshow(img_rgb)
                self.original_canvas.axes.set_title("原始图像 (Original)")
                self.original_canvas.axes.axis('off')
                self.original_canvas.draw()

                # Clear previous results
                self.result_canvas.axes.cla()
                self.result_canvas.axes.text(0.5, 0.5, '等待处理 (Awaiting Processing)...',
                                             ha='center', va='center', fontsize=10, wrap=True)
                self.result_canvas.axes.set_title("")
                self.result_canvas.axes.axis('off')
                self.result_canvas.draw()
                self.results_table.setRowCount(0)
                self.summary_text.clear()

                self.process_btn.setEnabled(True) # Enable processing now
                self.save_btn.setEnabled(False)   # Disable save until processed
                self.current_results = None       # Clear previous results data

            except FileNotFoundError as e:
                self.statusBar().showMessage(f"错误: {e}")
                QMessageBox.critical(self, "图像加载错误", f"无法加载图像文件:\n{e}")
                self.process_btn.setEnabled(False)
                self.save_btn.setEnabled(False)
                self.current_image_path = None
                self.image_path_edit.clear()
            except Exception as e:
                 self.statusBar().showMessage(f"加载图像时发生未知错误: {e}")
                 QMessageBox.critical(self, "图像加载错误", f"加载或显示图像时发生错误:\n{e}")
                 self.process_btn.setEnabled(False)
                 self.save_btn.setEnabled(False)
                 self.current_image_path = None
                 self.image_path_edit.clear()


    def process_current_image(self):
        """Starts the image processing thread."""
        if not self.model:
            QMessageBox.warning(self, "无法处理", "模型未加载或解密失败，无法处理图像。")
            return
        if not self.current_image_path:
            QMessageBox.warning(self, "无法处理", "请先加载一个图像文件。")
            return

        # Disable buttons during processing
        self.browse_image_btn.setEnabled(False)
        self.process_btn.setEnabled(False)
        self.save_btn.setEnabled(False)
        self.progress_bar.setValue(0)
        self.statusBar().showMessage("正在处理图像 (Processing image)...")
        QApplication.processEvents() # Update UI

        threshold = self.threshold_spin.value()

        # Create and start the processing thread
        self.processing_thread = ProcessingThread(self.model, self.current_image_path,
                                                  threshold, self.device)
        self.processing_thread.update_progress.connect(self.update_progress)
        self.processing_thread.processing_complete.connect(self.on_processing_complete)
        self.processing_thread.processing_error.connect(self.on_processing_error)
        self.processing_thread.finished.connect(self.on_processing_finished) # Re-enable buttons
        self.processing_thread.start()


    def update_progress(self, value):
        """Updates the progress bar."""
        self.progress_bar.setValue(value)


    def on_processing_complete(self, results):
        """Handles the results when processing is successful."""
        self.current_results = results # Store results
        self.progress_bar.setValue(100)
        self.statusBar().showMessage("处理完成 (Processing Complete)")

        try:
            # Display original image (might be already there, but refresh just in case)
            if 'original_image' in results:
                self.original_canvas.axes.cla()
                self.original_canvas.axes.imshow(results['original_image'])
                self.original_canvas.axes.set_title("原始图像 (Original)")
                self.original_canvas.axes.axis('off')
                self.original_canvas.draw()

            # Display visualization
            self.result_canvas.axes.cla()
            self.result_canvas.axes.imshow(results['visualization'])
            self.result_canvas.axes.set_title(f"检测到 {results['count']} 个区域")
            self.result_canvas.axes.axis('off')
            self.result_canvas.draw()

            # Populate results table
            self.results_table.setRowCount(results['count'])
            if 'region_info' in results:
                 for i, region in enumerate(results['region_info']):
                     # region_info is sorted by area, 'i' is the sorted index (0-based)
                     # region_num is the displayed number (1-based)
                     region_num_item = QTableWidgetItem(f"{i + 1}")
                     area_item = QTableWidgetItem(f"{region['area']:.2f}")
                     radius_item = QTableWidgetItem(f"{region['radius']:.2f}")
                     score_item = QTableWidgetItem(f"{region['score']:.3f}") # Add score

                     # Center align text in table cells
                     region_num_item.setTextAlignment(Qt.AlignCenter)
                     area_item.setTextAlignment(Qt.AlignCenter)
                     radius_item.setTextAlignment(Qt.AlignCenter)
                     score_item.setTextAlignment(Qt.AlignCenter)

                     self.results_table.setItem(i, 0, region_num_item)
                     self.results_table.setItem(i, 1, area_item)
                     self.results_table.setItem(i, 2, radius_item)
                     self.results_table.setItem(i, 3, score_item) # Column 3 for score
            else: # Fallback if region_info structure isn't present
                self.results_table.setRowCount(0) # Or handle old 'areas'/'radii' if needed

            # Populate summary text
            summary = (
                f"图像文件 (Image File): {os.path.basename(self.current_image_path)}\n"
                f"检测阈值 (Threshold): {self.threshold_spin.value():.2f}\n\n"
                f"检测到的区域数量 (Detected Regions): {results['count']}\n"
                f"总面积 (Total Area): {results['total_area']:.2f} px\n"
                f"平均面积 (Average Area): {results['average_area']:.2f} px\n"
                f"平均等效半径 (Average Radius): {results['average_radius']:.2f} px\n"
            )
            self.summary_text.setText(summary)

            self.save_btn.setEnabled(True) # Enable saving now

        except Exception as e:
            self.statusBar().showMessage(f"显示结果时出错: {e}")
            QMessageBox.critical(self, "结果显示错误", f"处理结果时发生错误:\n{e}")
            self.save_btn.setEnabled(False)


    def on_processing_error(self, error_message):
        """Handles errors that occur during processing."""
        self.progress_bar.setValue(0) # Reset progress bar
        self.statusBar().showMessage(f"处理错误 (Processing Error)")
        QMessageBox.critical(self, "处理错误", error_message)
        self.save_btn.setEnabled(False) # Cannot save if processing failed
        self.current_results = None


    def on_processing_finished(self):
        """Called when the processing thread finishes, regardless of success."""
        # Re-enable buttons that should be active after processing attempt
        self.browse_image_btn.setEnabled(self.model is not None) # Only if model is loaded
        self.process_btn.setEnabled(self.model is not None and self.current_image_path is not None)
        # Save button state is handled by complete/error handlers


    def save_results(self):
        """Saves the visualization, detailed data (CSV), and summary."""
        if not self.current_results:
            QMessageBox.warning(self, "无法保存", "没有可保存的结果。请先成功处理一张图像。")
            return

        options = QFileDialog.Options()
        # Suggest a base filename based on the input image
        base_name = os.path.splitext(os.path.basename(self.current_image_path))[0]
        # Use QFileDialog.getSaveFileName for better control, though directory selection is also fine
        # Let's stick to directory selection as in the original code for simplicity here:
        save_dir = QFileDialog.getExistingDirectory(self, "选择保存结果的目录 (Select Directory to Save Results)",
                                                     "", options=options)
        if not save_dir:
            self.statusBar().showMessage("保存已取消 (Save cancelled)")
            return

        self.statusBar().showMessage("正在保存结果 (Saving results)...")
        QApplication.processEvents()

        try:
            # 1. Save Visualization Image
            img_path = os.path.join(save_dir, f"{base_name}_检测结果.png")
            self.result_canvas.fig.savefig(img_path, dpi=150, bbox_inches='tight')

            # 2. Save Detailed Data (CSV)
            csv_path = os.path.join(save_dir, f"{base_name}_区域数据.csv")
            if 'region_info' in self.current_results:
                 data_for_csv = []
                 # Use sorted region_info for CSV output
                 for i, region in enumerate(self.current_results['region_info']):
                     data_for_csv.append({
                         '区域编号': i + 1,
                         '面积 (px)': f"{region['area']:.2f}",
                         '等效半径 (px)': f"{region['radius']:.2f}",
                         '置信度': f"{region['score']:.4f}",
                         '边界框 (x1,y1,x2,y2)': f"{region['box'][0]:.1f},{region['box'][1]:.1f},{region['box'][2]:.1f},{region['box'][3]:.1f}"
                     })
                 df = pd.DataFrame(data_for_csv)
                 df.to_csv(csv_path, index=False, encoding='utf-8-sig') # utf-8-sig for Excel compatibility
            else:
                 print("Warning: 'region_info' not found in results, cannot save detailed CSV.")

            # 3. Save Summary Text
            summary_path = os.path.join(save_dir, f"{base_name}_摘要.txt")
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(self.summary_text.toPlainText())

            self.statusBar().showMessage(f"结果已成功保存到 {save_dir}")
            QMessageBox.information(self, "保存完成", f"可视化图像、CSV数据和摘要已保存到:\n{save_dir}")

        except Exception as e:
            self.statusBar().showMessage(f"保存结果时出错: {e}")
            QMessageBox.critical(self, "保存错误", f"保存结果失败: {e}")
            import traceback
            traceback.print_exc()


# --- Main Execution Block ---
if __name__ == "__main__":
    # Ensure crypto is checked before proceeding
    if not CRYPTO_AVAILABLE:
        # Error message already shown during import check or sys.exit called
        print("Cryptography library check failed. Exiting.")
        sys.exit(1)

    # Set High DPI scaling for better visuals on modern displays (optional)
    # QApplication.setAttribute(Qt.AA_EnableHighDpiScaling, True)
    # QApplication.setAttribute(Qt.AA_UseHighDpiPixmaps, True)

    app = QApplication(sys.argv)
    app.setStyle('Fusion') # Or 'Windows', 'macOS'

    window = RegionDetectorApp()
    window.show()

    sys.exit(app.exec_())
